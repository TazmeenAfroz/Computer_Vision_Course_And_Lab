{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c676691a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/tazmeen/anaconda3/lib/python3.12/site-packages (4.10.0)\n",
      "✓ Successfully installed opencv-python\n",
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: absl-py in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from mediapipe) (2.3.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from mediapipe) (24.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from mediapipe) (25.2.10)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: matplotlib in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from mediapipe) (3.10.0)\n",
      "Requirement already satisfied: numpy<2 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from mediapipe) (1.26.4)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from mediapipe) (4.25.3)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Using cached sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting sentencepiece (from mediapipe)\n",
      "  Using cached sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: CFFI>=1.0 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from jax->mediapipe) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.12 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from jax->mediapipe) (1.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pycparser in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "Using cached mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl (35.6 MB)\n",
      "Using cached sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
      "Using cached jax-0.7.1-py3-none-any.whl (2.8 MB)\n",
      "Downloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl (81.2 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/81.2 MB\u001b[0m \u001b[31m9.2 kB/s\u001b[0m eta \u001b[36m1:37:36\u001b[0mm\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 98, in read\n",
      "    data: bytes = self.__fp.read(amt)\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/http/client.py\", line 479, in read\n",
      "    s = self.fp.read(amt)\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_internal/commands/install.py\", line 386, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_internal/operations/prepare.py\", line 554, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_internal/operations/prepare.py\", line 469, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_internal/network/download.py\", line 184, in __call__\n",
      "    for chunk in chunks:\n",
      "                 ^^^^^^\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_internal/cli/progress_bars.py\", line 55, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "                 ^^^^^^^^\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_internal/network/utils.py\", line 65, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n",
      "    with self._error_catcher():\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/tazmeen/anaconda3/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Failed to install mediapipe\n",
      "Requirement already satisfied: pyautogui in /home/tazmeen/anaconda3/lib/python3.12/site-packages (0.9.54)\n",
      "Requirement already satisfied: python3-Xlib in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from pyautogui) (0.15)\n",
      "Requirement already satisfied: pymsgbox in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from pyautogui) (1.0.9)\n",
      "Requirement already satisfied: pytweening>=1.0.4 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from pyautogui) (1.2.0)\n",
      "Requirement already satisfied: pyscreeze>=0.1.21 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from pyautogui) (1.0.1)\n",
      "Requirement already satisfied: pygetwindow>=0.0.5 in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from pyautogui) (0.0.9)\n",
      "Requirement already satisfied: mouseinfo in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from pyautogui) (0.1.3)\n",
      "Requirement already satisfied: pyrect in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from pygetwindow>=0.0.5->pyautogui) (0.2.0)\n",
      "Requirement already satisfied: pyperclip in /home/tazmeen/anaconda3/lib/python3.12/site-packages (from mouseinfo->pyautogui) (1.9.0)\n",
      "✓ Successfully installed pyautogui\n",
      "Requirement already satisfied: numpy in /home/tazmeen/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "✓ Successfully installed numpy\n",
      "\n",
      "All packages installation completed!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_packages():\n",
    "    packages = [\n",
    "        'opencv-python',\n",
    "        'mediapipe',\n",
    "        'pyautogui',\n",
    "        'numpy'\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "            print(f\"✓ Successfully installed {package}\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"✗ Failed to install {package}\")\n",
    "\n",
    "# Run installation\n",
    "install_packages()\n",
    "print(\"\\nAll packages installation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80c0231",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Eye-Tracking Virtual Keyboard and Mouse Control System\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# This system uses MediaPipe for eye tracking and OpenCV for webcam input\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyautogui\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "# Eye-Tracking Virtual Keyboard and Mouse Control System\n",
    "# This system uses MediaPipe for eye tracking and OpenCV for webcam input\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import threading\n",
    "import time\n",
    "import math\n",
    "from collections import deque\n",
    "\n",
    "# Disable pyautogui failsafe for smooth operation\n",
    "pyautogui.FAILSAFE = False\n",
    "\n",
    "class EyeTracker:\n",
    "    def __init__(self):\n",
    "        # Initialize MediaPipe face mesh\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.face_mesh = self.mp_face_mesh.FaceMesh(\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        \n",
    "        # Eye landmarks indices\n",
    "        self.LEFT_EYE = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]\n",
    "        self.RIGHT_EYE = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246]\n",
    "        \n",
    "        # Calibration points for screen mapping\n",
    "        self.calibration_points = []\n",
    "        self.screen_width, self.screen_height = pyautogui.size()\n",
    "        \n",
    "        # Smoothing buffer for eye positions\n",
    "        self.eye_positions = deque(maxlen=10)\n",
    "        \n",
    "        # Blink detection\n",
    "        self.blink_threshold = 0.25\n",
    "        self.blink_consecutive_frames = 3\n",
    "        self.blink_counter = 0\n",
    "        self.is_blinking = False\n",
    "        \n",
    "        # Click states\n",
    "        self.left_click_enabled = False\n",
    "        self.right_click_enabled = False\n",
    "        \n",
    "    def get_eye_aspect_ratio(self, eye_landmarks):\n",
    "        \"\"\"Calculate Eye Aspect Ratio for blink detection\"\"\"\n",
    "        # Vertical eye landmarks\n",
    "        A = np.linalg.norm(np.array(eye_landmarks[1]) - np.array(eye_landmarks[5]))\n",
    "        B = np.linalg.norm(np.array(eye_landmarks[2]) - np.array(eye_landmarks[4]))\n",
    "        # Horizontal eye landmark\n",
    "        C = np.linalg.norm(np.array(eye_landmarks[0]) - np.array(eye_landmarks[3]))\n",
    "        \n",
    "        ear = (A + B) / (2.0 * C)\n",
    "        return ear\n",
    "    \n",
    "    def get_gaze_direction(self, landmarks, frame_shape):\n",
    "        \"\"\"Extract gaze direction from eye landmarks\"\"\"\n",
    "        h, w = frame_shape[:2]\n",
    "        \n",
    "        # Get eye center points\n",
    "        left_eye_center = np.mean([[landmarks[i].x * w, landmarks[i].y * h] for i in self.LEFT_EYE], axis=0)\n",
    "        right_eye_center = np.mean([[landmarks[i].x * w, landmarks[i].y * h] for i in self.RIGHT_EYE], axis=0)\n",
    "        \n",
    "        # Average both eyes for more stable tracking\n",
    "        gaze_point = (left_eye_center + right_eye_center) / 2\n",
    "        \n",
    "        return gaze_point\n",
    "    \n",
    "    def detect_blink(self, landmarks):\n",
    "        \"\"\"Detect eye blinks\"\"\"\n",
    "        # Get eye landmarks\n",
    "        left_eye_points = [[landmarks[i].x, landmarks[i].y] for i in self.LEFT_EYE]\n",
    "        right_eye_points = [[landmarks[i].x, landmarks[i].y] for i in self.RIGHT_EYE]\n",
    "        \n",
    "        # Calculate EAR for both eyes\n",
    "        left_ear = self.get_eye_aspect_ratio(left_eye_points[:6])  # Use first 6 points\n",
    "        right_ear = self.get_eye_aspect_ratio(right_eye_points[:6])\n",
    "        \n",
    "        ear = (left_ear + right_ear) / 2.0\n",
    "        \n",
    "        if ear < self.blink_threshold:\n",
    "            self.blink_counter += 1\n",
    "        else:\n",
    "            if self.blink_counter >= self.blink_consecutive_frames:\n",
    "                return True\n",
    "            self.blink_counter = 0\n",
    "        \n",
    "        return False\n",
    "\n",
    "class VirtualKeyboard:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Virtual Eye-Controlled Keyboard\")\n",
    "        self.root.geometry(\"1200x400\")\n",
    "        self.root.configure(bg='black')\n",
    "        \n",
    "        # Keyboard layout\n",
    "        self.keys_layout = [\n",
    "            ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0', 'Backspace'],\n",
    "            ['Q', 'W', 'E', 'R', 'T', 'Y', 'U', 'I', 'O', 'P', 'Delete'],\n",
    "            ['A', 'S', 'D', 'F', 'G', 'H', 'J', 'K', 'L', 'Enter'],\n",
    "            ['Z', 'X', 'C', 'V', 'B', 'N', 'M', 'Space', 'Shift'],\n",
    "            ['Ctrl', 'Alt', 'Tab', 'Esc', 'Home', 'End', 'Up', 'Down', 'Left', 'Right']\n",
    "        ]\n",
    "        \n",
    "        self.buttons = {}\n",
    "        self.current_highlighted = None\n",
    "        self.text_output = tk.StringVar()\n",
    "        \n",
    "        self.setup_keyboard()\n",
    "        \n",
    "    def setup_keyboard(self):\n",
    "        # Text output area\n",
    "        output_frame = tk.Frame(self.root, bg='black')\n",
    "        output_frame.pack(pady=10)\n",
    "        \n",
    "        tk.Label(output_frame, text=\"Output:\", fg='white', bg='black', font=('Arial', 12)).pack(side=tk.LEFT)\n",
    "        output_entry = tk.Entry(output_frame, textvariable=self.text_output, width=60, font=('Arial', 12))\n",
    "        output_entry.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        # Keyboard frame\n",
    "        keyboard_frame = tk.Frame(self.root, bg='black')\n",
    "        keyboard_frame.pack(pady=20)\n",
    "        \n",
    "        for row_idx, row in enumerate(self.keys_layout):\n",
    "            row_frame = tk.Frame(keyboard_frame, bg='black')\n",
    "            row_frame.pack(pady=2)\n",
    "            \n",
    "            for col_idx, key in enumerate(row):\n",
    "                width = 8\n",
    "                if key in ['Space']:\n",
    "                    width = 20\n",
    "                elif key in ['Backspace', 'Delete', 'Enter', 'Shift']:\n",
    "                    width = 12\n",
    "                \n",
    "                btn = tk.Button(\n",
    "                    row_frame,\n",
    "                    text=key,\n",
    "                    width=width,\n",
    "                    height=2,\n",
    "                    font=('Arial', 10, 'bold'),\n",
    "                    bg='gray30',\n",
    "                    fg='white',\n",
    "                    activebackground='blue',\n",
    "                    command=lambda k=key: self.key_pressed(k)\n",
    "                )\n",
    "                btn.pack(side=tk.LEFT, padx=1, pady=1)\n",
    "                self.buttons[key] = btn\n",
    "    \n",
    "    def key_pressed(self, key):\n",
    "        \"\"\"Handle key press events\"\"\"\n",
    "        if key == 'Space':\n",
    "            self.text_output.set(self.text_output.get() + ' ')\n",
    "        elif key == 'Backspace':\n",
    "            current = self.text_output.get()\n",
    "            self.text_output.set(current[:-1])\n",
    "        elif key == 'Delete':\n",
    "            self.text_output.set(\"\")\n",
    "        elif key == 'Enter':\n",
    "            self.text_output.set(self.text_output.get() + '\\n')\n",
    "        elif key in ['Ctrl', 'Alt', 'Tab', 'Esc', 'Home', 'End', 'Up', 'Down', 'Left', 'Right', 'Shift']:\n",
    "            # Handle special keys with pyautogui\n",
    "            pyautogui.press(key.lower())\n",
    "        else:\n",
    "            self.text_output.set(self.text_output.get() + key.lower())\n",
    "    \n",
    "    def highlight_key(self, key):\n",
    "        \"\"\"Highlight a key when eye is focused on it\"\"\"\n",
    "        if self.current_highlighted:\n",
    "            self.current_highlighted.configure(bg='gray30')\n",
    "        \n",
    "        if key in self.buttons:\n",
    "            self.buttons[key].configure(bg='red')\n",
    "            self.current_highlighted = self.buttons[key]\n",
    "    \n",
    "    def get_key_at_position(self, x, y):\n",
    "        \"\"\"Get which key is at the given screen position\"\"\"\n",
    "        # Convert screen coordinates to keyboard coordinates\n",
    "        # This is a simplified version - you'd need more precise mapping\n",
    "        for key, button in self.buttons.items():\n",
    "            try:\n",
    "                btn_x = button.winfo_rootx()\n",
    "                btn_y = button.winfo_rooty()\n",
    "                btn_width = button.winfo_width()\n",
    "                btn_height = button.winfo_height()\n",
    "                \n",
    "                if btn_x <= x <= btn_x + btn_width and btn_y <= y <= btn_y + btn_height:\n",
    "                    return key\n",
    "            except:\n",
    "                continue\n",
    "        return None\n",
    "\n",
    "class EyeControlSystem:\n",
    "    def __init__(self):\n",
    "        self.eye_tracker = EyeTracker()\n",
    "        self.virtual_keyboard = VirtualKeyboard()\n",
    "        self.cap = None\n",
    "        self.running = False\n",
    "        \n",
    "        # Control modes\n",
    "        self.keyboard_mode = True\n",
    "        self.mouse_mode = False\n",
    "        \n",
    "        # Dwell time for selections (in seconds)\n",
    "        self.dwell_time = 2.0\n",
    "        self.current_dwell_start = None\n",
    "        self.current_target = None\n",
    "        \n",
    "    def start_camera(self):\n",
    "        \"\"\"Initialize camera\"\"\"\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        if not self.cap.isOpened():\n",
    "            print(\"Error: Could not open camera\")\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def process_frame(self):\n",
    "        \"\"\"Process each frame for eye tracking\"\"\"\n",
    "        if not self.cap:\n",
    "            return None\n",
    "            \n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return None\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)  # Mirror the frame\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.eye_tracker.face_mesh.process(rgb_frame)\n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # Get gaze direction\n",
    "                gaze_point = self.eye_tracker.get_gaze_direction(face_landmarks.landmark, frame.shape)\n",
    "                \n",
    "                # Smooth the gaze point\n",
    "                self.eye_tracker.eye_positions.append(gaze_point)\n",
    "                smoothed_gaze = np.mean(self.eye_tracker.eye_positions, axis=0)\n",
    "                \n",
    "                # Map to screen coordinates\n",
    "                screen_x = int(smoothed_gaze[0] * self.eye_tracker.screen_width / frame.shape[1])\n",
    "                screen_y = int(smoothed_gaze[1] * self.eye_tracker.screen_height / frame.shape[0])\n",
    "                \n",
    "                # Detect blinks for clicking\n",
    "                if self.eye_tracker.detect_blink(face_landmarks.landmark):\n",
    "                    if self.keyboard_mode:\n",
    "                        key = self.virtual_keyboard.get_key_at_position(screen_x, screen_y)\n",
    "                        if key:\n",
    "                            self.virtual_keyboard.key_pressed(key)\n",
    "                    elif self.mouse_mode:\n",
    "                        pyautogui.click(screen_x, screen_y)\n",
    "                \n",
    "                # Update interface\n",
    "                if self.keyboard_mode:\n",
    "                    key = self.virtual_keyboard.get_key_at_position(screen_x, screen_y)\n",
    "                    if key:\n",
    "                        self.virtual_keyboard.highlight_key(key)\n",
    "                elif self.mouse_mode:\n",
    "                    pyautogui.moveTo(screen_x, screen_y)\n",
    "                \n",
    "                # Draw eye tracking visualization\n",
    "                cv2.circle(frame, (int(smoothed_gaze[0]), int(smoothed_gaze[1])), 5, (0, 255, 0), -1)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Main execution loop\"\"\"\n",
    "        if not self.start_camera():\n",
    "            return\n",
    "        \n",
    "        self.running = True\n",
    "        \n",
    "        # Start keyboard in separate thread\n",
    "        keyboard_thread = threading.Thread(target=self.virtual_keyboard.root.mainloop)\n",
    "        keyboard_thread.daemon = True\n",
    "        keyboard_thread.start()\n",
    "        \n",
    "        while self.running:\n",
    "            frame = self.process_frame()\n",
    "            if frame is not None:\n",
    "                # Add control instructions\n",
    "                cv2.putText(frame, f\"Mode: {'Keyboard' if self.keyboard_mode else 'Mouse'}\", \n",
    "                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.putText(frame, \"Press 'k' for Keyboard, 'm' for Mouse, 'q' to quit\", \n",
    "                           (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, \"Blink to click/select\", \n",
    "                           (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                \n",
    "                cv2.imshow('Eye Tracking Control', frame)\n",
    "            \n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                self.running = False\n",
    "                break\n",
    "            elif key == ord('k'):\n",
    "                self.keyboard_mode = True\n",
    "                self.mouse_mode = False\n",
    "            elif key == ord('m'):\n",
    "                self.keyboard_mode = False\n",
    "                self.mouse_mode = True\n",
    "        \n",
    "        self.cleanup()\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up resources\"\"\"\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Initialize and run the system\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Eye-Tracking Keyboard and Mouse Control System\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Features:\")\n",
    "    print(\"- Virtual keyboard control with eye tracking\")\n",
    "    print(\"- Mouse control with eye movement\")\n",
    "    print(\"- Blink detection for clicking/selecting\")\n",
    "    print(\"- Real-time webcam processing\")\n",
    "    print(\"\\nInstructions:\")\n",
    "    print(\"1. Look at keys to highlight them\")\n",
    "    print(\"2. Blink to select/click\")\n",
    "    print(\"3. Press 'k' for keyboard mode, 'm' for mouse mode\")\n",
    "    print(\"4. Press 'q' to quit\")\n",
    "    print(\"\\nStarting system...\")\n",
    "    \n",
    "    system = EyeControlSystem()\n",
    "    system.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb8082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Eye-Tracking System with Calibration and Advanced Features\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox\n",
    "import threading\n",
    "import time\n",
    "import math\n",
    "from collections import deque\n",
    "import json\n",
    "import os\n",
    "\n",
    "class AdvancedEyeTracker:\n",
    "    def __init__(self):\n",
    "        # Try to import mediapipe, fallback to basic tracking if not available\n",
    "        self.use_mediapipe = False\n",
    "        try:\n",
    "            import mediapipe as mp\n",
    "            self.mp_face_mesh = mp.solutions.face_mesh\n",
    "            self.face_mesh = self.mp_face_mesh.FaceMesh(\n",
    "                max_num_faces=1,\n",
    "                refine_landmarks=True,\n",
    "                min_detection_confidence=0.5,\n",
    "                min_tracking_confidence=0.5\n",
    "            )\n",
    "            self.use_mediapipe = True\n",
    "            print(\"✓ MediaPipe loaded successfully\")\n",
    "        except ImportError:\n",
    "            print(\"⚠ MediaPipe not available, using basic face detection\")\n",
    "            # Initialize basic face/eye detection\n",
    "            self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "            self.eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "        \n",
    "        # Screen dimensions\n",
    "        self.screen_width, self.screen_height = pyautogui.size()\n",
    "        \n",
    "        # Calibration data\n",
    "        self.calibration_data = []\n",
    "        self.is_calibrated = False\n",
    "        \n",
    "        # Smoothing and tracking\n",
    "        self.gaze_history = deque(maxlen=10)\n",
    "        self.blink_threshold = 0.3\n",
    "        self.last_blink_time = 0\n",
    "        self.blink_cooldown = 0.5\n",
    "        \n",
    "        # Settings\n",
    "        self.sensitivity = 1.0\n",
    "        self.dwell_time = 1.5\n",
    "        \n",
    "    def calibrate(self, screen_points, eye_points):\n",
    "        \"\"\"Calibrate eye tracking to screen coordinates\"\"\"\n",
    "        if len(screen_points) >= 4 and len(eye_points) >= 4:\n",
    "            # Use polynomial transformation for calibration\n",
    "            screen_points = np.array(screen_points, dtype=np.float32)\n",
    "            eye_points = np.array(eye_points, dtype=np.float32)\n",
    "            \n",
    "            # Calculate transformation matrix\n",
    "            self.transform_matrix = cv2.getPerspectiveTransform(\n",
    "                eye_points[:4], screen_points[:4]\n",
    "            )\n",
    "            self.is_calibrated = True\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def track_eyes_basic(self, frame):\n",
    "        \"\"\"Basic eye tracking using Haar cascades\"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = self.face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "        gaze_point = None\n",
    "        for (x, y, w, h) in faces:\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            \n",
    "            eyes = self.eye_cascade.detectMultiScale(roi_gray)\n",
    "            if len(eyes) >= 2:\n",
    "                # Get center point between eyes\n",
    "                eye_centers = []\n",
    "                for (ex, ey, ew, eh) in eyes[:2]:\n",
    "                    eye_center = (x + ex + ew//2, y + ey + eh//2)\n",
    "                    eye_centers.append(eye_center)\n",
    "                    cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "                \n",
    "                if len(eye_centers) == 2:\n",
    "                    gaze_point = np.mean(eye_centers, axis=0)\n",
    "                    cv2.circle(frame, tuple(map(int, gaze_point)), 5, (255, 0, 0), -1)\n",
    "        \n",
    "        return gaze_point\n",
    "    \n",
    "    def track_eyes_mediapipe(self, frame):\n",
    "        \"\"\"Advanced eye tracking using MediaPipe\"\"\"\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.face_mesh.process(rgb_frame)\n",
    "        \n",
    "        gaze_point = None\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                h, w = frame.shape[:2]\n",
    "                \n",
    "                # Eye landmarks (simplified)\n",
    "                left_eye_indices = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246]\n",
    "                right_eye_indices = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]\n",
    "                \n",
    "                # Calculate eye centers\n",
    "                left_eye_points = [(int(face_landmarks.landmark[i].x * w), \n",
    "                                  int(face_landmarks.landmark[i].y * h)) for i in left_eye_indices]\n",
    "                right_eye_points = [(int(face_landmarks.landmark[i].x * w), \n",
    "                                   int(face_landmarks.landmark[i].y * h)) for i in right_eye_indices]\n",
    "                \n",
    "                left_center = np.mean(left_eye_points, axis=0)\n",
    "                right_center = np.mean(right_eye_points, axis=0)\n",
    "                \n",
    "                gaze_point = (left_center + right_center) / 2\n",
    "                \n",
    "                # Draw eye regions\n",
    "                for point in left_eye_points + right_eye_points:\n",
    "                    cv2.circle(frame, point, 1, (0, 255, 0), -1)\n",
    "                \n",
    "                cv2.circle(frame, tuple(map(int, gaze_point)), 5, (255, 0, 0), -1)\n",
    "        \n",
    "        return gaze_point\n",
    "    \n",
    "    def map_to_screen(self, gaze_point, frame_shape):\n",
    "        \"\"\"Map gaze point to screen coordinates\"\"\"\n",
    "        if not self.is_calibrated:\n",
    "            # Simple proportional mapping\n",
    "            h, w = frame_shape[:2]\n",
    "            screen_x = int(gaze_point[0] * self.screen_width / w)\n",
    "            screen_y = int(gaze_point[1] * self.screen_height / h)\n",
    "        else:\n",
    "            # Use calibration matrix\n",
    "            point = np.array([[gaze_point]], dtype=np.float32)\n",
    "            transformed = cv2.perspectiveTransform(point, self.transform_matrix)\n",
    "            screen_x, screen_y = transformed[0][0]\n",
    "        \n",
    "        # Apply sensitivity and smoothing\n",
    "        self.gaze_history.append((screen_x, screen_y))\n",
    "        if len(self.gaze_history) > 1:\n",
    "            smoothed = np.mean(self.gaze_history, axis=0)\n",
    "            return int(smoothed[0]), int(smoothed[1])\n",
    "        \n",
    "        return int(screen_x), int(screen_y)\n",
    "\n",
    "class EnhancedVirtualKeyboard:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Advanced Eye-Controlled Keyboard\")\n",
    "        self.root.geometry(\"1400x500\")\n",
    "        self.root.configure(bg='#1a1a1a')\n",
    "        \n",
    "        # Keyboard layouts\n",
    "        self.qwerty_layout = [\n",
    "            ['`', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '-', '=', 'Backspace'],\n",
    "            ['Tab', 'Q', 'W', 'E', 'R', 'T', 'Y', 'U', 'I', 'O', 'P', '[', ']', '\\\\'],\n",
    "            ['Caps', 'A', 'S', 'D', 'F', 'G', 'H', 'J', 'K', 'L', ';', \"'\", 'Enter'],\n",
    "            ['Shift', 'Z', 'X', 'C', 'V', 'B', 'N', 'M', ',', '.', '/', 'Shift'],\n",
    "            ['Ctrl', 'Win', 'Alt', 'Space', 'Alt', 'Menu', 'Ctrl', '←', '↑', '↓', '→']\n",
    "        ]\n",
    "        \n",
    "        self.buttons = {}\n",
    "        self.current_highlighted = None\n",
    "        self.text_output = tk.StringVar()\n",
    "        self.caps_lock = False\n",
    "        self.shift_pressed = False\n",
    "        \n",
    "        # Dwell selection\n",
    "        self.dwell_start_time = None\n",
    "        self.dwell_key = None\n",
    "        self.dwell_duration = 2.0\n",
    "        \n",
    "        self.setup_ui()\n",
    "        \n",
    "    def setup_ui(self):\n",
    "        # Control panel\n",
    "        control_frame = tk.Frame(self.root, bg='#1a1a1a')\n",
    "        control_frame.pack(pady=10)\n",
    "        \n",
    "        tk.Label(control_frame, text=\"Eye-Controlled Keyboard\", \n",
    "                fg='white', bg='#1a1a1a', font=('Arial', 16, 'bold')).pack()\n",
    "        \n",
    "        # Text output\n",
    "        output_frame = tk.Frame(self.root, bg='#1a1a1a')\n",
    "        output_frame.pack(pady=10)\n",
    "        \n",
    "        tk.Label(output_frame, text=\"Output:\", fg='white', bg='#1a1a1a', \n",
    "                font=('Arial', 12)).pack(anchor='w')\n",
    "        \n",
    "        self.text_area = tk.Text(output_frame, width=80, height=4, font=('Arial', 12))\n",
    "        self.text_area.pack(pady=5)\n",
    "        \n",
    "        # Keyboard\n",
    "        keyboard_frame = tk.Frame(self.root, bg='#1a1a1a')\n",
    "        keyboard_frame.pack(pady=20)\n",
    "        \n",
    "        for row_idx, row in enumerate(self.qwerty_layout):\n",
    "            row_frame = tk.Frame(keyboard_frame, bg='#1a1a1a')\n",
    "            row_frame.pack(pady=2)\n",
    "            \n",
    "            for key in row:\n",
    "                width = self.get_key_width(key)\n",
    "                \n",
    "                btn = tk.Button(\n",
    "                    row_frame,\n",
    "                    text=key,\n",
    "                    width=width,\n",
    "                    height=2,\n",
    "                    font=('Arial', 10, 'bold'),\n",
    "                    bg='#404040',\n",
    "                    fg='white',\n",
    "                    activebackground='#0066cc',\n",
    "                    relief='raised',\n",
    "                    command=lambda k=key: self.key_pressed(k)\n",
    "                )\n",
    "                btn.pack(side=tk.LEFT, padx=1, pady=1)\n",
    "                self.buttons[key] = btn\n",
    "        \n",
    "        # Status bar\n",
    "        status_frame = tk.Frame(self.root, bg='#1a1a1a')\n",
    "        status_frame.pack(side=tk.BOTTOM, fill=tk.X, pady=5)\n",
    "        \n",
    "        self.status_label = tk.Label(status_frame, text=\"Ready\", \n",
    "                                   fg='white', bg='#1a1a1a', font=('Arial', 10))\n",
    "        self.status_label.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        # Dwell progress bar\n",
    "        self.dwell_progress = ttk.Progressbar(status_frame, length=200, mode='determinate')\n",
    "        self.dwell_progress.pack(side=tk.RIGHT, padx=10)\n",
    "    \n",
    "    def get_key_width(self, key):\n",
    "        \"\"\"Get appropriate width for different keys\"\"\"\n",
    "        if key == 'Space':\n",
    "            return 25\n",
    "        elif key in ['Backspace', 'Enter', 'Shift', 'Tab']:\n",
    "            return 12\n",
    "        elif key in ['Caps', 'Ctrl', 'Alt', 'Win']:\n",
    "            return 8\n",
    "        else:\n",
    "            return 4\n",
    "    \n",
    "    def key_pressed(self, key):\n",
    "        \"\"\"Handle key press events\"\"\"\n",
    "        current_text = self.text_area.get('1.0', tk.END)\n",
    "        \n",
    "        if key == 'Space':\n",
    "            self.text_area.insert(tk.END, ' ')\n",
    "        elif key == 'Backspace':\n",
    "            self.text_area.delete('end-2c', 'end-1c')\n",
    "        elif key == 'Enter':\n",
    "            self.text_area.insert(tk.END, '\\n')\n",
    "        elif key == 'Tab':\n",
    "            self.text_area.insert(tk.END, '\\t')\n",
    "        elif key == 'Caps':\n",
    "            self.caps_lock = not self.caps_lock\n",
    "            self.update_caps_indicator()\n",
    "        elif key == 'Shift':\n",
    "            self.shift_pressed = not self.shift_pressed\n",
    "            self.update_shift_indicator()\n",
    "        elif key in ['Ctrl', 'Alt', 'Win', 'Menu']:\n",
    "            # Handle modifier keys\n",
    "            pass\n",
    "        elif key in ['←', '↑', '↓', '→']:\n",
    "            # Handle arrow keys\n",
    "            if key == '←':\n",
    "                self.text_area.mark_set(tk.INSERT, 'insert-1c')\n",
    "            elif key == '→':\n",
    "                self.text_area.mark_set(tk.INSERT, 'insert+1c')\n",
    "        else:\n",
    "            # Regular character\n",
    "            char = key\n",
    "            if self.caps_lock or self.shift_pressed:\n",
    "                char = char.upper()\n",
    "            else:\n",
    "                char = char.lower()\n",
    "            \n",
    "            self.text_area.insert(tk.END, char)\n",
    "            \n",
    "            if self.shift_pressed:\n",
    "                self.shift_pressed = False\n",
    "                self.update_shift_indicator()\n",
    "        \n",
    "        self.text_area.see(tk.END)\n",
    "    \n",
    "    def update_caps_indicator(self):\n",
    "        \"\"\"Update caps lock indicator\"\"\"\n",
    "        if self.caps_lock:\n",
    "            self.buttons['Caps'].configure(bg='#cc6600')\n",
    "        else:\n",
    "            self.buttons['Caps'].configure(bg='#404040')\n",
    "    \n",
    "    def update_shift_indicator(self):\n",
    "        \"\"\"Update shift indicator\"\"\"\n",
    "        color = '#cc6600' if self.shift_pressed else '#404040'\n",
    "        for key in ['Shift']:\n",
    "            if key in self.buttons:\n",
    "                self.buttons[key].configure(bg=color)\n",
    "    \n",
    "    def highlight_key(self, key, progress=0):\n",
    "        \"\"\"Highlight key with dwell progress\"\"\"\n",
    "        # Reset previous highlight\n",
    "        if self.current_highlighted and self.current_highlighted != key:\n",
    "            self.buttons[self.current_highlighted].configure(bg='#404040')\n",
    "        \n",
    "        if key in self.buttons:\n",
    "            # Color intensity based on dwell progress\n",
    "            intensity = min(255, int(100 + progress * 155))\n",
    "            color = f'#{intensity:02x}4040'\n",
    "            self.buttons[key].configure(bg=color)\n",
    "            self.current_highlighted = key\n",
    "            \n",
    "            # Update progress bar\n",
    "            self.dwell_progress['value'] = progress * 100\n",
    "    \n",
    "    def get_key_at_position(self, x, y):\n",
    "        \"\"\"Get key at screen position\"\"\"\n",
    "        self.root.update()  # Ensure geometry is current\n",
    "        \n",
    "        for key, button in self.buttons.items():\n",
    "            try:\n",
    "                btn_x = button.winfo_rootx()\n",
    "                btn_y = button.winfo_rooty()\n",
    "                btn_width = button.winfo_width()\n",
    "                btn_height = button.winfo_height()\n",
    "                \n",
    "                if (btn_x <= x <= btn_x + btn_width and \n",
    "                    btn_y <= y <= btn_y + btn_height):\n",
    "                    return key\n",
    "            except tk.TclError:\n",
    "                continue\n",
    "        return None\n",
    "    \n",
    "    def update_status(self, message):\n",
    "        \"\"\"Update status message\"\"\"\n",
    "        self.status_label.configure(text=message)\n",
    "\n",
    "class EyeControlSystem:\n",
    "    def __init__(self):\n",
    "        self.eye_tracker = AdvancedEyeTracker()\n",
    "        self.virtual_keyboard = EnhancedVirtualKeyboard()\n",
    "        self.cap = None\n",
    "        self.running = False\n",
    "        \n",
    "        # Control modes\n",
    "        self.keyboard_mode = True\n",
    "        self.mouse_mode = False\n",
    "        self.calibration_mode = False\n",
    "        \n",
    "        # Dwell selection\n",
    "        self.dwell_start_time = None\n",
    "        self.current_target = None\n",
    "        self.dwell_duration = 2.0\n",
    "        \n",
    "        # Calibration\n",
    "        self.calibration_points = []\n",
    "        self.calibration_eye_points = []\n",
    "        \n",
    "    def start_camera(self):\n",
    "        \"\"\"Initialize camera with error handling\"\"\"\n",
    "        for i in range(3):  # Try multiple camera indices\n",
    "            self.cap = cv2.VideoCapture(i)\n",
    "            if self.cap.isOpened():\n",
    "                # Set camera properties for better performance\n",
    "                self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "                self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "                self.cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "                print(f\"✓ Camera {i} initialized successfully\")\n",
    "                return True\n",
    "        \n",
    "        print(\"✗ Could not initialize any camera\")\n",
    "        messagebox.showerror(\"Error\", \"Could not access camera\")\n",
    "        return False\n",
    "    \n",
    "    def calibrate_system(self):\n",
    "        \"\"\"Interactive calibration process\"\"\"\n",
    "        if not self.cap:\n",
    "            return\n",
    "        \n",
    "        calibration_points = [\n",
    "            (100, 100), (self.eye_tracker.screen_width - 100, 100),\n",
    "            (100, self.eye_tracker.screen_height - 100), \n",
    "            (self.eye_tracker.screen_width - 100, self.eye_tracker.screen_height - 100),\n",
    "            (self.eye_tracker.screen_width // 2, self.eye_tracker.screen_height // 2)\n",
    "        ]\n",
    "        \n",
    "        print(\"Starting calibration...\")\n",
    "        self.virtual_keyboard.update_status(\"Calibration mode - Look at the red circles\")\n",
    "        \n",
    "        eye_points = []\n",
    "        \n",
    "        for i, (cx, cy) in enumerate(calibration_points):\n",
    "            print(f\"Look at point {i+1}/5\")\n",
    "            \n",
    "            # Create calibration window\n",
    "            cal_window = np.zeros((self.eye_tracker.screen_height, \n",
    "                                 self.eye_tracker.screen_width, 3), dtype=np.uint8)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            collected_points = []\n",
    "            \n",
    "            while time.time() - start_time < 3.0:  # 3 seconds per point\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    continue\n",
    "                \n",
    "                frame = cv2.flip(frame, 1)\n",
    "                \n",
    "                # Track eyes\n",
    "                if self.eye_tracker.use_mediapipe:\n",
    "                    gaze_point = self.eye_tracker.track_eyes_mediapipe(frame)\n",
    "                else:\n",
    "                    gaze_point = self.eye_tracker.track_eyes_basic(frame)\n",
    "                \n",
    "                if gaze_point is not None:\n",
    "                    collected_points.append(gaze_point)\n",
    "                \n",
    "                # Draw calibration point\n",
    "                cv2.circle(cal_window, (cx, cy), 20, (0, 0, 255), -1)\n",
    "                cv2.circle(cal_window, (cx, cy), 40, (0, 0, 255), 2)\n",
    "                \n",
    "                # Show progress\n",
    "                progress = (time.time() - start_time) / 3.0\n",
    "                cv2.putText(cal_window, f\"Point {i+1}/5 - {progress*100:.0f}%\", \n",
    "                           (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                \n",
    "                cv2.imshow('Calibration', cal_window)\n",
    "                cv2.imshow('Eye Tracking', frame)\n",
    "                \n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "            if collected_points:\n",
    "                avg_point = np.mean(collected_points, axis=0)\n",
    "                eye_points.append(avg_point)\n",
    "                print(f\"Collected point {i+1}: {avg_point}\")\n",
    "        \n",
    "        cv2.destroyWindow('Calibration')\n",
    "        \n",
    "        # Perform calibration\n",
    "        if len(eye_points) >= 4:\n",
    "            success = self.eye_tracker.calibrate(calibration_points, eye_points)\n",
    "            if success:\n",
    "                print(\"✓ Calibration successful!\")\n",
    "                self.virtual_keyboard.update_status(\"Calibrated - Ready for eye control\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"✗ Calibration failed\")\n",
    "                self.virtual_keyboard.update_status(\"Calibration failed\")\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def process_frame(self):\n",
    "        \"\"\"Process each frame for eye tracking\"\"\"\n",
    "        if not self.cap:\n",
    "            return None\n",
    "        \n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return None\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Track eyes\n",
    "        if self.eye_tracker.use_mediapipe:\n",
    "            gaze_point = self.eye_tracker.track_eyes_mediapipe(frame)\n",
    "        else:\n",
    "            gaze_point = self.eye_tracker.track_eyes_basic(frame)\n",
    "        \n",
    "        if gaze_point is not None:\n",
    "            # Map to screen coordinates\n",
    "            screen_x, screen_y = self.eye_tracker.map_to_screen(gaze_point, frame.shape)\n",
    "            \n",
    "            # Handle different modes\n",
    "            if self.keyboard_mode:\n",
    "                self.handle_keyboard_mode(screen_x, screen_y)\n",
    "            elif self.mouse_mode:\n",
    "                self.handle_mouse_mode(screen_x, screen_y)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def handle_keyboard_mode(self, screen_x, screen_y):\n",
    "        \"\"\"Handle keyboard interaction\"\"\"\n",
    "        key = self.virtual_keyboard.get_key_at_position(screen_x, screen_y)\n",
    "        \n",
    "        if key:\n",
    "            current_time = time.time()\n",
    "            \n",
    "            if key != self.current_target:\n",
    "                # New target\n",
    "                self.current_target = key\n",
    "                self.dwell_start_time = current_time\n",
    "                \n",
    "            else:\n",
    "                # Same target - check dwell time\n",
    "                dwell_elapsed = current_time - self.dwell_start_time\n",
    "                progress = min(1.0, dwell_elapsed / self.dwell_duration)\n",
    "                \n",
    "                self.virtual_keyboard.highlight_key(key, progress)\n",
    "                \n",
    "                if dwell_elapsed >= self.dwell_duration:\n",
    "                    # Execute key press\n",
    "                    self.virtual_keyboard.key_pressed(key)\n",
    "                    self.current_target = None\n",
    "                    self.dwell_start_time = None\n",
    "                    print(f\"Key pressed: {key}\")\n",
    "        else:\n",
    "            # No target\n",
    "            if self.current_target:\n",
    "                self.virtual_keyboard.highlight_key(self.current_target, 0)\n",
    "            self.current_target = None\n",
    "            self.dwell_start_time = None\n",
    "    \n",
    "    def handle_mouse_mode(self, screen_x, screen_y):\n",
    "        \"\"\"Handle mouse control\"\"\"\n",
    "        # Smooth mouse movement\n",
    "        try:\n",
    "            pyautogui.moveTo(screen_x, screen_y, duration=0.01)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Main execution loop\"\"\"\n",
    "        if not self.start_camera():\n",
    "            return\n",
    "        \n",
    "        # Start keyboard interface\n",
    "        keyboard_thread = threading.Thread(target=self.virtual_keyboard.root.mainloop)\n",
    "        keyboard_thread.daemon = True\n",
    "        keyboard_thread.start()\n",
    "        \n",
    "        print(\"System ready!\")\n",
    "        print(\"Controls:\")\n",
    "        print(\"- 'c' to calibrate\")\n",
    "        print(\"- 'k' for keyboard mode\")\n",
    "        print(\"- 'm' for mouse mode\")\n",
    "        print(\"- 'q' to quit\")\n",
    "        \n",
    "        self.running = True\n",
    "        \n",
    "        while self.running:\n",
    "            frame = self.process_frame()\n",
    "            \n",
    "            if frame is not None:\n",
    "                # Add UI overlay\n",
    "                self.add_overlay(frame)\n",
    "                cv2.imshow('Eye Control System', frame)\n",
    "            \n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                self.running = False\n",
    "                break\n",
    "            elif key == ord('c'):\n",
    "                self.calibrate_system()\n",
    "            elif key == ord('k'):\n",
    "                self.keyboard_mode = True\n",
    "                self.mouse_mode = False\n",
    "                self.virtual_keyboard.update_status(\"Keyboard mode active\")\n",
    "            elif key == ord('m'):\n",
    "                self.keyboard_mode = False\n",
    "                self.mouse_mode = True\n",
    "                self.virtual_keyboard.update_status(\"Mouse mode active\")\n",
    "        \n",
    "        self.cleanup()\n",
    "    \n",
    "    def add_overlay(self, frame):\n",
    "        \"\"\"Add information overlay to frame\"\"\"\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        # Status text\n",
    "        mode_text = \"Keyboard\" if self.keyboard_mode else \"Mouse\"\n",
    "        cv2.putText(frame, f\"Mode: {mode_text}\", (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        calib_status = \"Calibrated\" if self.eye_tracker.is_calibrated else \"Not Calibrated\"\n",
    "        cv2.putText(frame, f\"Calibration: {calib_status}\", (10, 70), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "        \n",
    "        # Control instructions\n",
    "        cv2.putText(frame, \"Controls: 'c'=Calibrate 'k'=Keyboard 'm'=Mouse 'q'=Quit\", \n",
    "                   (10, h-20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "        \n",
    "        # Dwell indicator\n",
    "        if self.current_target and self.dwell_start_time:\n",
    "            elapsed = time.time() - self.dwell_start_time\n",
    "            progress = min(1.0, elapsed / self.dwell_duration)\n",
    "            \n",
    "            # Progress bar\n",
    "            bar_width = 200\n",
    "            bar_height = 20\n",
    "            bar_x = w - bar_width - 10\n",
    "            bar_y = 10\n",
    "            \n",
    "            cv2.rectangle(frame, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), \n",
    "                         (50, 50, 50), -1)\n",
    "            cv2.rectangle(frame, (bar_x, bar_y), \n",
    "                         (bar_x + int(bar_width * progress), bar_y + bar_height), \n",
    "                         (0, 255, 0), -1)\n",
    "            cv2.putText(frame, f\"Target: {self.current_target}\", \n",
    "                       (bar_x, bar_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up resources\"\"\"\n",
    "        self.running = False\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        try:\n",
    "            self.virtual_keyboard.root.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Demo function to test the system\n",
    "def run_eye_control_demo():\n",
    "    \"\"\"Run the eye control system demo\"\"\"\n",
    "    print(\"🔥 Advanced Eye-Controlled Keyboard & Mouse System\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Features:\")\n",
    "    print(\"✓ Advanced eye tracking with MediaPipe fallback\")\n",
    "    print(\"✓ Full QWERTY virtual keyboard\")\n",
    "    print(\"✓ Mouse control with eye movement\")\n",
    "    print(\"✓ Calibration system for accuracy\")\n",
    "    print(\"✓ Dwell-time selection (no clicking needed)\")\n",
    "    print(\"✓ Real-time visual feedback\")\n",
    "    print(\"✓ Smooth eye movement tracking\")\n",
    "    print(\"\")\n",
    "    print(\"Getting ready...\")\n",
    "    \n",
    "    try:\n",
    "        system = EyeControlSystem()\n",
    "        system.run()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nSystem stopped by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Run the demo\n",
    "if __name__ == \"__main__\":\n",
    "    run_eye_control_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bfb4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified Eye-Tracking System (OpenCV Only) - Ready to Test\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import threading\n",
    "import time\n",
    "import math\n",
    "\n",
    "# Simple eye tracking using OpenCV only\n",
    "class SimpleEyeTracker:\n",
    "    def __init__(self):\n",
    "        # Load cascade classifiers\n",
    "        try:\n",
    "            self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "            self.eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "            print(\"✓ OpenCV cascades loaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading cascades: {e}\")\n",
    "            return\n",
    "        \n",
    "        # Mouse control (if pyautogui is available)\n",
    "        self.mouse_control = False\n",
    "        try:\n",
    "            import pyautogui\n",
    "            self.pyautogui = pyautogui\n",
    "            self.mouse_control = True\n",
    "            self.screen_width, self.screen_height = pyautogui.size()\n",
    "            pyautogui.FAILSAFE = False\n",
    "            print(\"✓ Mouse control enabled\")\n",
    "        except ImportError:\n",
    "            print(\"⚠ PyAutoGUI not available - mouse control disabled\")\n",
    "        \n",
    "        # Tracking variables\n",
    "        self.last_gaze_point = None\n",
    "        self.gaze_history = []\n",
    "        self.max_history = 5\n",
    "        \n",
    "    def detect_eyes_and_face(self, frame):\n",
    "        \"\"\"Detect face and eyes in frame\"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        \n",
    "        results = {'faces': [], 'eyes': [], 'gaze_point': None}\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            results['faces'].append((x, y, w, h))\n",
    "            \n",
    "            # Region of interest for eyes\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            \n",
    "            # Detect eyes in face region\n",
    "            eyes = self.eye_cascade.detectMultiScale(roi_gray, 1.1, 3)\n",
    "            \n",
    "            eye_centers = []\n",
    "            for (ex, ey, ew, eh) in eyes:\n",
    "                # Adjust coordinates to full frame\n",
    "                eye_x = x + ex + ew // 2\n",
    "                eye_y = y + ey + eh // 2\n",
    "                eye_centers.append((eye_x, eye_y))\n",
    "                results['eyes'].append((x + ex, y + ey, ew, eh))\n",
    "            \n",
    "            # Calculate gaze point (center between eyes)\n",
    "            if len(eye_centers) >= 2:\n",
    "                gaze_x = sum(center[0] for center in eye_centers[:2]) // 2\n",
    "                gaze_y = sum(center[1] for center in eye_centers[:2]) // 2\n",
    "                results['gaze_point'] = (gaze_x, gaze_y)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def smooth_gaze(self, gaze_point):\n",
    "        \"\"\"Apply smoothing to gaze point\"\"\"\n",
    "        if gaze_point is None:\n",
    "            return self.last_gaze_point\n",
    "        \n",
    "        self.gaze_history.append(gaze_point)\n",
    "        if len(self.gaze_history) > self.max_history:\n",
    "            self.gaze_history.pop(0)\n",
    "        \n",
    "        if len(self.gaze_history) > 0:\n",
    "            avg_x = sum(p[0] for p in self.gaze_history) / len(self.gaze_history)\n",
    "            avg_y = sum(p[1] for p in self.gaze_history) / len(self.gaze_history)\n",
    "            smoothed = (int(avg_x), int(avg_y))\n",
    "            self.last_gaze_point = smoothed\n",
    "            return smoothed\n",
    "        \n",
    "        return gaze_point\n",
    "\n",
    "class SimpleVirtualKeyboard:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Simple Eye-Controlled Keyboard\")\n",
    "        self.root.geometry(\"900x300\")\n",
    "        self.root.configure(bg='#2d2d2d')\n",
    "        \n",
    "        # Simple keyboard layout\n",
    "        self.layout = [\n",
    "            ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0', 'Del'],\n",
    "            ['Q', 'W', 'E', 'R', 'T', 'Y', 'U', 'I', 'O', 'P', 'Clear'],\n",
    "            ['A', 'S', 'D', 'F', 'G', 'H', 'J', 'K', 'L', 'Enter'],\n",
    "            ['Z', 'X', 'C', 'V', 'B', 'N', 'M', 'Space']\n",
    "        ]\n",
    "        \n",
    "        self.buttons = {}\n",
    "        self.highlighted_key = None\n",
    "        self.setup_keyboard()\n",
    "        \n",
    "        # Output text\n",
    "        self.output_text = \"\"\n",
    "        \n",
    "    def setup_keyboard(self):\n",
    "        # Title\n",
    "        title_label = tk.Label(self.root, text=\"Eye-Controlled Virtual Keyboard\", \n",
    "                              fg='white', bg='#2d2d2d', font=('Arial', 14, 'bold'))\n",
    "        title_label.pack(pady=5)\n",
    "        \n",
    "        # Output display\n",
    "        self.output_var = tk.StringVar()\n",
    "        output_frame = tk.Frame(self.root, bg='#2d2d2d')\n",
    "        output_frame.pack(pady=5)\n",
    "        \n",
    "        tk.Label(output_frame, text=\"Output:\", fg='white', bg='#2d2d2d').pack(side=tk.LEFT)\n",
    "        self.output_entry = tk.Entry(output_frame, textvariable=self.output_var, \n",
    "                                   width=50, font=('Arial', 12))\n",
    "        self.output_entry.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        # Keyboard\n",
    "        keyboard_frame = tk.Frame(self.root, bg='#2d2d2d')\n",
    "        keyboard_frame.pack(pady=10)\n",
    "        \n",
    "        for row in self.layout:\n",
    "            row_frame = tk.Frame(keyboard_frame, bg='#2d2d2d')\n",
    "            row_frame.pack(pady=2)\n",
    "            \n",
    "            for key in row:\n",
    "                width = 8 if key != 'Space' else 20\n",
    "                \n",
    "                btn = tk.Button(row_frame, text=key, width=width, height=2,\n",
    "                              font=('Arial', 10, 'bold'), bg='#555', fg='white',\n",
    "                              command=lambda k=key: self.key_pressed(k))\n",
    "                btn.pack(side=tk.LEFT, padx=2)\n",
    "                self.buttons[key] = btn\n",
    "        \n",
    "        # Status label\n",
    "        self.status_label = tk.Label(self.root, text=\"Ready - Look at keys to highlight\", \n",
    "                                   fg='yellow', bg='#2d2d2d', font=('Arial', 10))\n",
    "        self.status_label.pack(pady=5)\n",
    "    \n",
    "    def key_pressed(self, key):\n",
    "        \"\"\"Handle virtual key presses\"\"\"\n",
    "        if key == 'Space':\n",
    "            self.output_text += ' '\n",
    "        elif key == 'Del':\n",
    "            self.output_text = self.output_text[:-1]\n",
    "        elif key == 'Clear':\n",
    "            self.output_text = \"\"\n",
    "        elif key == 'Enter':\n",
    "            self.output_text += '\\n'\n",
    "        else:\n",
    "            self.output_text += key.lower()\n",
    "        \n",
    "        self.output_var.set(self.output_text)\n",
    "        print(f\"Key pressed: {key}\")\n",
    "    \n",
    "    def highlight_key(self, key):\n",
    "        \"\"\"Highlight a key\"\"\"\n",
    "        # Reset previous highlight\n",
    "        if self.highlighted_key and self.highlighted_key in self.buttons:\n",
    "            self.buttons[self.highlighted_key].configure(bg='#555')\n",
    "        \n",
    "        # Highlight new key\n",
    "        if key in self.buttons:\n",
    "            self.buttons[key].configure(bg='#ff6600')\n",
    "            self.highlighted_key = key\n",
    "            self.status_label.configure(text=f\"Focusing on: {key}\")\n",
    "    \n",
    "    def get_key_at_position(self, x, y):\n",
    "        \"\"\"Get key at screen coordinates\"\"\"\n",
    "        self.root.update()\n",
    "        \n",
    "        for key, button in self.buttons.items():\n",
    "            try:\n",
    "                btn_x = button.winfo_rootx()\n",
    "                btn_y = button.winfo_rooty()\n",
    "                btn_width = button.winfo_width()\n",
    "                btn_height = button.winfo_height()\n",
    "                \n",
    "                if (btn_x <= x <= btn_x + btn_width and \n",
    "                    btn_y <= y <= btn_y + btn_height):\n",
    "                    return key\n",
    "            except:\n",
    "                continue\n",
    "        return None\n",
    "\n",
    "class SimpleEyeControlSystem:\n",
    "    def __init__(self):\n",
    "        self.tracker = SimpleEyeTracker()\n",
    "        self.keyboard = SimpleVirtualKeyboard()\n",
    "        self.cap = None\n",
    "        self.running = False\n",
    "        \n",
    "        # Selection timing\n",
    "        self.focus_start_time = None\n",
    "        self.current_focus_key = None\n",
    "        self.selection_delay = 2.0  # 2 seconds to select\n",
    "        \n",
    "        # Modes\n",
    "        self.keyboard_mode = True\n",
    "        self.mouse_mode = False\n",
    "        \n",
    "    def start_camera(self):\n",
    "        \"\"\"Start camera capture\"\"\"\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        if not self.cap.isOpened():\n",
    "            print(\"❌ Could not open camera\")\n",
    "            return False\n",
    "        \n",
    "        print(\"✅ Camera started successfully\")\n",
    "        return True\n",
    "    \n",
    "    def process_frame(self):\n",
    "        \"\"\"Process camera frame\"\"\"\n",
    "        if not self.cap:\n",
    "            return None\n",
    "        \n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return None\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)  # Mirror image\n",
    "        \n",
    "        # Detect eyes and face\n",
    "        detection_results = self.tracker.detect_eyes_and_face(frame)\n",
    "        \n",
    "        # Draw detections\n",
    "        self.draw_detections(frame, detection_results)\n",
    "        \n",
    "        # Handle gaze tracking\n",
    "        if detection_results['gaze_point']:\n",
    "            gaze_point = self.tracker.smooth_gaze(detection_results['gaze_point'])\n",
    "            if gaze_point:\n",
    "                self.handle_gaze(gaze_point, frame.shape)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def draw_detections(self, frame, results):\n",
    "        \"\"\"Draw detection results on frame\"\"\"\n",
    "        # Draw face rectangles\n",
    "        for (x, y, w, h) in results['faces']:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        \n",
    "        # Draw eye rectangles\n",
    "        for (x, y, w, h) in results['eyes']:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw gaze point\n",
    "        if results['gaze_point']:\n",
    "            gx, gy = results['gaze_point']\n",
    "            cv2.circle(frame, (gx, gy), 10, (0, 0, 255), -1)\n",
    "            cv2.circle(frame, (gx, gy), 20, (0, 0, 255), 2)\n",
    "    \n",
    "    def handle_gaze(self, gaze_point, frame_shape):\n",
    "        \"\"\"Handle gaze point for interaction\"\"\"\n",
    "        if self.keyboard_mode:\n",
    "            self.handle_keyboard_gaze(gaze_point)\n",
    "        elif self.mouse_mode and self.tracker.mouse_control:\n",
    "            self.handle_mouse_gaze(gaze_point, frame_shape)\n",
    "    \n",
    "    def handle_keyboard_gaze(self, gaze_point):\n",
    "        \"\"\"Handle gaze for keyboard interaction\"\"\"\n",
    "        # Map gaze to screen coordinates (approximate)\n",
    "        screen_x = int(gaze_point[0] * 2)  # Simple scaling\n",
    "        screen_y = int(gaze_point[1] * 2)\n",
    "        \n",
    "        # Get key at position\n",
    "        key = self.keyboard.get_key_at_position(screen_x, screen_y)\n",
    "        \n",
    "        if key:\n",
    "            current_time = time.time()\n",
    "            \n",
    "            if key != self.current_focus_key:\n",
    "                # New key focused\n",
    "                self.current_focus_key = key\n",
    "                self.focus_start_time = current_time\n",
    "                self.keyboard.highlight_key(key)\n",
    "            else:\n",
    "                # Same key - check selection time\n",
    "                if current_time - self.focus_start_time >= self.selection_delay:\n",
    "                    # Select the key\n",
    "                    self.keyboard.key_pressed(key)\n",
    "                    self.current_focus_key = None\n",
    "                    self.focus_start_time = None\n",
    "        else:\n",
    "            # No key focused\n",
    "            self.current_focus_key = None\n",
    "            self.focus_start_time = None\n",
    "    \n",
    "    def handle_mouse_gaze(self, gaze_point, frame_shape):\n",
    "        \"\"\"Handle gaze for mouse control\"\"\"\n",
    "        h, w = frame_shape[:2]\n",
    "        # Map to screen coordinates\n",
    "        screen_x = int(gaze_point[0] * self.tracker.screen_width / w)\n",
    "        screen_y = int(gaze_point[1] * self.tracker.screen_height / h)\n",
    "        \n",
    "        try:\n",
    "            self.tracker.pyautogui.moveTo(screen_x, screen_y, duration=0.1)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    def add_overlay_info(self, frame):\n",
    "        \"\"\"Add information overlay to frame\"\"\"\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        # Mode indicator\n",
    "        mode_text = \"KEYBOARD\" if self.keyboard_mode else \"MOUSE\"\n",
    "        cv2.putText(frame, f\"Mode: {mode_text}\", (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # Instructions\n",
    "        cv2.putText(frame, \"Controls: K=Keyboard, M=Mouse, Q=Quit\", \n",
    "                   (10, h - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        # Selection timer\n",
    "        if self.current_focus_key and self.focus_start_time:\n",
    "            elapsed = time.time() - self.focus_start_time\n",
    "            progress = min(1.0, elapsed / self.selection_delay)\n",
    "            \n",
    "            # Progress bar\n",
    "            bar_width = 200\n",
    "            bar_height = 20\n",
    "            bar_x = w - bar_width - 10\n",
    "            bar_y = 50\n",
    "            \n",
    "            cv2.rectangle(frame, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), \n",
    "                         (50, 50, 50), -1)\n",
    "            cv2.rectangle(frame, (bar_x, bar_y), \n",
    "                         (bar_x + int(bar_width * progress), bar_y + bar_height), \n",
    "                         (0, 255, 0), -1)\n",
    "            cv2.putText(frame, f\"Selecting: {self.current_focus_key}\", \n",
    "                       (bar_x, bar_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Main run loop\"\"\"\n",
    "        if not self.start_camera():\n",
    "            return\n",
    "        \n",
    "        # Start keyboard in separate thread\n",
    "        keyboard_thread = threading.Thread(target=self.keyboard.root.mainloop)\n",
    "        keyboard_thread.daemon = True\n",
    "        keyboard_thread.start()\n",
    "        \n",
    "        print(\"\\n🚀 Simple Eye Control System Started!\")\n",
    "        print(\"👁️  Look at keyboard keys to highlight them\")\n",
    "        print(\"⏱️  Hold gaze for 2 seconds to select\")\n",
    "        print(\"⌨️  Press 'K' for keyboard mode\")\n",
    "        print(\"🖱️  Press 'M' for mouse mode\")\n",
    "        print(\"❌ Press 'Q' to quit\")\n",
    "        \n",
    "        self.running = True\n",
    "        \n",
    "        while self.running:\n",
    "            frame = self.process_frame()\n",
    "            if frame is not None:\n",
    "                self.add_overlay_info(frame)\n",
    "                cv2.imshow('Simple Eye Control', frame)\n",
    "            \n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                self.running = False\n",
    "                break\n",
    "            elif key == ord('k'):\n",
    "                self.keyboard_mode = True\n",
    "                self.mouse_mode = False\n",
    "                print(\"🔄 Switched to Keyboard mode\")\n",
    "            elif key == ord('m'):\n",
    "                self.keyboard_mode = False\n",
    "                self.mouse_mode = True\n",
    "                print(\"🔄 Switched to Mouse mode\")\n",
    "        \n",
    "        self.cleanup()\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up resources\"\"\"\n",
    "        print(\"\\n🛑 Shutting down...\")\n",
    "        self.running = False\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        try:\n",
    "            self.keyboard.root.quit()\n",
    "        except:\n",
    "            pass\n",
    "        print(\"✅ Cleanup completed\")\n",
    "\n",
    "# Quick test function\n",
    "def test_simple_eye_control():\n",
    "    \"\"\"Test the simple eye control system\"\"\"\n",
    "    print(\"🎯 Simple Eye Control System - OpenCV Version\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"This version uses only OpenCV and works immediately!\")\n",
    "    print(\"\")\n",
    "    \n",
    "    try:\n",
    "        system = SimpleEyeControlSystem()\n",
    "        system.run()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n⚠️ System stopped by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Run the simple version\n",
    "test_simple_eye_control()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
